# 16. Зависимые и независимые случайные величины

Вспомним определение независимости двух событий:

::: info `def` Независимые события
События А и В называются \textbf{независимыми}, если \(\mathbb{P}(AB) = \mathbb{P}(A)\cdot \mathbb{P}(B).\)
:::

## Определение независимости случайных величин

::: info `def` Независимые случайные величины
Случайные величины являются \textbf{независимыми}, если функция распределения случайного вектора равна произведению маргинальных функций распределения для любых компонент.

\[\mathbb{F}(x,y) = \mathbb{F}_\xi(x) \cdot \mathbb{F}_\eta(y)\]
:::

Чтобы доказать зависимость, достаточно найти хотя бы одну группу, которая не удовлетворяет условию независимости случайных величин. Однако для подтверждения независимости между компонентами нужно рассмотреть все возможные комбинации.

::: warning `cor` Следствие для непрерывных случайных величин
Совместная плотность компонент случайного вектора равна произведению маргинальных плотностей компонент.

\[\rho(x,y) = \rho_\xi(x) \cdot \rho_\eta(y)\]
:::

::: warning `cor` Следствие для дискретных случайных величин
Совместная вероятность компонент случайного вектора равна произведению маргинальных вероятностей компонент.

\[\mathbb{P}(\xi=x, \eta=y) = \mathbb{P}(\xi = x) \cdot \mathbb{P}(\eta = y)\]
:::

::: details `exm` Пример 
Игральная кость бросается дважды. Построим закон распределения двумерного случайного вектора \((\xi,\eta)\), где \(\xi \ -\) количество выпадений шести очков, а \(\eta \ -\) количество выпадений нечетной цифры (1, 3, 5).

{|c|c|c|c|c|}
| $\eta / \xi$ | 0 | 1 | 2 | $P(\eta = y)$ | 
|:---:|:---:|:---:|:---:|:---:|
|0 | $\dfrac{4}{36}$ | $\dfrac{4}{36}$ | $\dfrac{1}{36}$ | $\dfrac{9}{36}$ |
|1 | $\dfrac{12}{36}$ | $\dfrac{6}{36}$ | 0 | $\dfrac{18}{36}$ | 
|2 | $\dfrac{9}{36}$ | 0 | 0 | $\dfrac{9}{36}$ | 
|$P(\xi = x)$ | $\dfrac{25}{36}$ | $\dfrac{10}{36}$ | $\dfrac{1}{36}$ | 1 | 

Проведем проверку на независимость: \(\dfrac{4}{36} \neq \dfrac{9}{36} \cdot \dfrac{25}{36} \Rightarrow\) зависимы.
:::

## Ковариация и коэффициент корреляции

### Ковариация

\[\text{cov}(\xi, \eta) = \mathbb{M}((\xi - \mathbb{M}_\xi)(\eta - \mathbb{M}_\eta))\]

::: warning `cor` Совместное математическое ожидание
\[\mathbb{M}_{\xi\eta} = \mathbb{M}_\xi \cdot \mathbb{M}_\eta + \text{cov}(\xi,\eta)\]
:::

::: warning `cor` Совместная дисперсия
\[\mathbb{D}_{\xi\eta} = \mathbb{D}_\xi + \mathbb{D}_\eta + 2\text{cov}(\xi,\eta)\]
:::

Для практики будет использоваться формула \(\text{cov}(\xi,\eta) = \mathbb{M}_{\xi\eta}-\mathbb{M}_\xi \cdot \mathbb{M}_\eta\).

Свойства ковариации:

1. По определению ковариации от перестановки компонент результат не изменится: \(\text{cov}(\xi,\eta) = \text{cov}(\eta, \xi)\).
    
    ::: details `prf` Доказательство 
    Так как ковариация - это произведение, то от перестановки множителей само произведение не меняется.
    :::
2. Ковариация случайной величины и константы равна 0.

    ::: details `prf` Доказательство 
    \(]\ C = const: \ \text{cov}(\xi, C) = \mathbb{M}_{\xi C}-\mathbb{M}_\xi \cdot \mathbb{M}_C = 0 - \mathbb{M}_\xi \cdot 0 = 0\)
    :::
3. Ковариация независимых случайных величин равна 0.
4. Ковариация случайной величины самой с собой равна ее дисперсии.

    ::: details `prf` Доказательство 
    \(\text{cov}(\xi, \xi) = \mathbb{M}((\xi - \mathbb{M}_\xi)(\xi - \mathbb{M}_\xi)) = \mathbb{M}(\xi - \mathbb{M}_\xi)^2 = \mathbb{D}_\xi\)
    :::
5. Линейность по каждому аргументу: \(\text{cov}(a\xi_1 + b\xi_2, \eta) = a\cdot\text{cov}(\xi_1, \eta) + b\cdot\text{cov}(\xi_2, \eta)\)
6. Аналог неравенства Коши: \(|\text{cov}(a\xi, \eta)| \leq \sigma_\xi\cdot\sigma_\eta \)

::: tip `tip` Мое замечание
Чем плоха ковариация? Она зависит от размерности и не показывает степень зависимости. Поэтому на практике рассматривают нормированную ковариацию - коэффициент корреляции.
:::

### Корреляция

::: info `def` Коэффициент корреляции
Еще называется "коэффициент корреляции Пирсона"
\[\rho_{\xi\eta}=\dfrac{\text{cov}(\xi, \eta)}{\sigma_\xi\sigma_\eta}\]
:::

#### Значения коэффициента корреляции

| $\rho $ | Интерпретация | 
|:---:|:---:|
|\(\approx 1\) | Полное совпадение | 
|\(\approx 0\) | Отсутствие линейной зависимости | 
|\(\approx -1\) | Полная противоположность | 

#### Свойства коэффициента корреляции

1. \(|\rho_{\xi\eta}| \leq 1\)
::: details `prf` Доказательство  
Пусть \(X, Y \ -\) случайные величины.
    
\(X_1 = \dfrac{X - \mathbb{M}_X}{\sigma_X}, \ Y_1 = \dfrac{Y - \mathbb{M}_Y}{\sigma_Y} \ - \) стандартизация заданных случайных величин. 
    ::: warning `fct` Факт 
    Стандартизация случайной величины \(X_1 = \dfrac{X - \mathbb{M}_X}{\sigma_X}\) обладает следующими свойствами:
    1) \(\mathbb{M}_{X_1} = 0\)
    ::: details `prf` Доказательство 
    \(\mathbb{M}_{X_1} = \mathbb{M}[\dfrac{X - \mathbb{M}_X}{\sigma_X}] = \dfrac{1}{\sigma_X}(\mathbb{M}_X - \mathbb{M}_X) = \dfrac{1}{\sigma_X}\cdot0=0.\)
    :::
    2) \(\mathbb{D}_{X_1} = 1\)
    ::: details `prf` Доказательство 
    \(\mathbb{D}_{X_1} = \dfrac{\mathbb{D}[X - \mathbb{M}_{X}]}{\sigma_{X}^2} = \dfrac{\mathbb{D}_X}{\mathbb{D}_X} = 1.\)
    :::
:::

    \(\mathbb{D}[X_1 \pm Y_1] = \mathbb{D}_{X_1} + \mathbb{D}_{Y_1} \pm 2\text{cov}(X_1, Y_1)\)

    \(\mathbb{D}[X_1 \pm Y_1] = 1 + 1 \pm 2\text{cov}(X_1, Y_1)\)

    \(\mathbb{D}[X_1 \pm Y_1] = 2 \pm 2\text{cov}(X_1, Y_1)\)

    \(\mathbb{D}[X_1 \pm Y_1] = 2(1 \pm \text{cov}(X_1, Y_1))\)

    Вычислим ковариацию случайных величин:

    \(\text{cov}(X_1, Y_1) = \mathbb{M}[(\dfrac{X - \mathbb{M}_X}{\sqrt{\mathbb{D}_X}})(\dfrac{Y - \mathbb{M}_Y}{\sqrt{\mathbb{D}_Y}})] \Rightarrow \) 
    
    \(\dfrac{\text{cov}(X_1, Y_1)}{\sqrt{\mathbb{D}_X \mathbb{D}_Y}} = \mathbb{M}[({X - \mathbb{M}_X})({Y - \mathbb{M}_Y})] = \rho(X,Y)\) по определению.

    По свойству дисперсии она не может быть меньше нуля. Подставим полученное значение:

    \( 0 \leq 2(1 \pm \rho(X, Y))\)
    
    \( 0 \leq 1 \pm \rho(X, Y)\)

    \(-1 \leq \rho(X, Y) \leq 1\)
:::

2. Тогда и только тогда, когда случайные величины линейно зависимы, их коэффициент корреляции по модулю равен 1.
::: details `prf` Доказательство
*Необходимость:* Пусть \(Y = aX+b.\) Тогда математическое ожидание \(\mathbb{M}_Y = a(\mathbb{M}_X) + b,\) а дисперсия \(\mathbb{D}_Y = a^2\mathbb{D}_X\).

Посчитаем коэффициент корреляции: \(\mathbb{M}((X - \mathbb{M}_X)(Y - \mathbb{M}_Y)) = \dfrac{\mathbb{M}((X - \mathbb{M}_X)(aX - a\mathbb{M}_X)
    )}{|a|\sqrt{\mathbb{D}_X \mathbb{D}_X}} = \dfrac{a\mathbb{D}_X}{|a|\mathbb{D}_X} = \pm a.\)

*Достаточность:* Пусть X и Y линейно связаны.
:::