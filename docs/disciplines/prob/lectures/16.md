# 16. Зависимые и независимые случайные величины

Вспомним определение независимости двух событий:

::: info `def` Независимые события
События А и В называются **независимыми**, если $\mathbb{P}(AB) = \mathbb{P}(A)\cdot \mathbb{P}(B).$
:::

## Определение независимости случайных величин

::: info `def` Независимые случайные величины
Случайные величины являются **независимыми**, если функция распределения случайного вектора равна произведению маргинальных функций распределения для любых компонент.

$$\mathbb{F}(x,y) = \mathbb{F}_\xi(x) \cdot \mathbb{F}_\eta(y)$$
:::

Чтобы доказать зависимость, достаточно найти хотя бы одну группу, которая не удовлетворяет условию независимости случайных величин. Однако для подтверждения независимости между компонентами нужно рассмотреть все возможные комбинации.

::: warning `cor` Следствие для непрерывных случайных величин
Совместная плотность компонент случайного вектора равна произведению маргинальных плотностей компонент.

$$\rho(x,y) = \rho_\xi(x) \cdot \rho_\eta(y)$$
:::

::: warning `cor` Следствие для дискретных случайных величин
Совместная вероятность компонент случайного вектора равна произведению маргинальных вероятностей компонент.

$$\mathbb{P}(\xi=x, \eta=y) = \mathbb{P}(\xi = x) \cdot \mathbb{P}(\eta = y)$$
:::

::: details `exm` Пример 
Игральная кость бросается дважды. Построим закон распределения двумерного случайного вектора $(\xi,\eta)$, где $\xi \ -$ количество выпадений шести очков, а $\eta \ -$ количество выпадений нечетной цифры (1, 3, 5).

| $\eta / \xi$ | 0 | 1 | 2 | $P(\eta = y)$ | 
|:---:|:---:|:---:|:---:|:---:|
|0 | $\dfrac{4}{36}$ | $\dfrac{4}{36}$ | $\dfrac{1}{36}$ | $\dfrac{9}{36}$ |
|1 | $\dfrac{12}{36}$ | $\dfrac{6}{36}$ | 0 | $\dfrac{18}{36}$ | 
|2 | $\dfrac{9}{36}$ | 0 | 0 | $\dfrac{9}{36}$ | 
|$P(\xi = x)$ | $\dfrac{25}{36}$ | $\dfrac{10}{36}$ | $\dfrac{1}{36}$ | 1 | 

Проведем проверку на независимость: $\dfrac{4}{36} \neq \dfrac{9}{36} \cdot \dfrac{25}{36} \Rightarrow$ зависимы.
:::

## Ковариация и коэффициент корреляции

### Ковариация

$$\text{cov}(\xi, \eta) = \mathbb{M}((\xi - \mathbb{M}_\xi)(\eta - \mathbb{M}_\eta))$$

::: warning `cor` Совместное математическое ожидание
$$\mathbb{M}_{\xi\eta} = \mathbb{M}_\xi \cdot \mathbb{M}_\eta + \text{cov}(\xi,\eta)$$
:::

::: warning `cor` Совместная дисперсия
$$\mathbb{D}_{\xi\eta} = \mathbb{D}_\xi + \mathbb{D}_\eta + 2\text{cov}(\xi,\eta)$$
:::

Для практики будет использоваться формула $\text{cov}(\xi,\eta) = \mathbb{M}_{\xi\eta}-\mathbb{M}_\xi \cdot \mathbb{M}_\eta$.

Свойства ковариации:

1. По определению ковариации от перестановки компонент результат не изменится: $\text{cov}(\xi,\eta) = \text{cov}(\eta, \xi)$.
    
    ::: details `prf` Доказательство 
    Так как ковариация - это произведение, то от перестановки множителей само произведение не меняется.
    :::
2. Ковариация случайной величины и константы равна 0.

    ::: details `prf` Доказательство 
    $]\ C = const: \ \text{cov}(\xi, C) = \mathbb{M}_{\xi C}-\mathbb{M}_\xi \cdot \mathbb{M}_C = 0 - \mathbb{M}_\xi \cdot 0 = 0$
    :::
3. Ковариация независимых случайных величин равна 0.
4. Ковариация случайной величины самой с собой равна ее дисперсии.

    ::: details `prf` Доказательство 
    $\text{cov}(\xi, \xi) = \mathbb{M}((\xi - \mathbb{M}_\xi)(\xi - \mathbb{M}_\xi)) = \mathbb{M}(\xi - \mathbb{M}_\xi)^2 = \mathbb{D}_\xi$
    :::
5. Линейность по каждому аргументу: $\text{cov}(a\xi_1 + b\xi_2, \eta) = a\cdot\text{cov}(\xi_1, \eta) + b\cdot\text{cov}(\xi_2, \eta)$
6. Аналог неравенства Коши: $|\text{cov}(a\xi, \eta)| \leq \sigma_\xi\cdot\sigma_\eta$

::: tip `tip` Мое замечание
Чем плоха ковариация? Она зависит от размерности и не показывает степень зависимости. Поэтому на практике рассматривают нормированную ковариацию - коэффициент корреляции.
:::

### Корреляция

::: info `def` Коэффициент корреляции
Еще называется "коэффициент корреляции Пирсона"
$$\rho_{\xi\eta}=\dfrac{\text{cov}(\xi, \eta)}{\sigma_\xi\sigma_\eta}$$
:::

#### Значения коэффициента корреляции

| $\rho $ | Интерпретация | 
|:---:|:---:|
|$\approx 1$ | Полное совпадение | 
|$\approx 0$ | Отсутствие линейной зависимости | 
|$\approx -1$ | Полная противоположность | 

#### Свойства коэффициента корреляции

1. $|\rho_{\xi\eta}| \leq 1$

::: details `prf` Доказательство  
Пусть $X, Y \ -$ случайные величины.
    
$X_1 = \dfrac{X - \mathbb{M}_X}{\sigma_X}, \ Y_1 = \dfrac{Y - \mathbb{M}_Y}{\sigma_Y} \ -$ **стандартизация** заданных случайных величин. 

$\mathbb{D}[X_1 \pm Y_1] = \mathbb{D}_{X_1} + \mathbb{D}_{Y_1} \pm 2\text{cov}(X_1, Y_1)$

$\mathbb{D}[X_1 \pm Y_1] = 1 + 1 \pm 2\text{cov}(X_1, Y_1)$

$\mathbb{D}[X_1 \pm Y_1] = 2 \pm 2\text{cov}(X_1, Y_1)$

$\mathbb{D}[X_1 \pm Y_1] = 2(1 \pm \text{cov}(X_1, Y_1))$

Вычислим ковариацию случайных величин:

$\text{cov}(X_1, Y_1) = \mathbb{M}[(\dfrac{X - \mathbb{M}_X}{\sqrt{\mathbb{D}_X}})(\dfrac{Y - \mathbb{M}_Y}{\sqrt{\mathbb{D}_Y}})] \Rightarrow$ 
    
$\dfrac{\text{cov}(X_1, Y_1)}{\sqrt{\mathbb{D}_X \mathbb{D}_Y}} = \mathbb{M}[({X - \mathbb{M}_X})({Y - \mathbb{M}_Y})] = \rho(X,Y)$ по определению.

По свойству дисперсии она не может быть меньше нуля. Подставим полученное значение:

$0 \leq 2(1 \pm \rho(X, Y))$
    
$0 \leq 1 \pm \rho(X, Y)$

$-1 \leq \rho(X, Y) \leq 1$
:::

::: warning `fct` Факт 
Стандартизация случайной величины $X_1 = \dfrac{X - \mathbb{M}_X}{\sigma_X}$ обладает следующими свойствами:
1) $\mathbb{M}_{X_1} = 0$

    ::: details `prf` Доказательство 
    $\mathbb{M}_{X_1} = \mathbb{M}[\dfrac{X - \mathbb{M}_X}{\sigma_X}] = \dfrac{1}{\sigma_X}(\mathbb{M}_X - \mathbb{M}_X) = \dfrac{1}{\sigma_X}\cdot0=0.$
    :::
   
2) $\mathbb{D}_{X_1} = 1$
   
    ::: details `prf` Доказательство
    $\mathbb{D}_{X_1} = \dfrac{\mathbb{D}[X - \mathbb{M}_{X}]}{\sigma_{X}^2} = \dfrac{\mathbb{D}_X}{\mathbb{D}_X} = 1.$
    :::

3) Тогда и только тогда, когда случайные величины линейно зависимы, их коэффициент корреляции по модулю равен 1.

    ::: details `prf` Доказательство
    *Необходимость:* 

    Пусть $Y = aX+b.$ Тогда математическое ожидание $\mathbb{M}_Y = a(\mathbb{M}_X) + b,$ а дисперсия $\mathbb{D}_Y = a^2\mathbb{D}_X$.

    Посчитаем коэффициент корреляции: $\mathbb{M}((X - \mathbb{M}_X)(Y - \mathbb{M}_Y)) = \dfrac{\mathbb{M}((X - \mathbb{M}_X)(aX - a\mathbb{M}_X)
        )}{|a|\sqrt{\mathbb{D}_X \mathbb{D}_X}} = \dfrac{a\mathbb{D}_X}{|a|\mathbb{D}_X} = \pm a.$

    *Достаточность:* Пусть X и Y линейно связаны ($|\rho(X, Y)| = 1$).

    Пусть $X_1, \ Y_1 \ -$ стандартизированные случайные величины.

    $\mathbb{D}(X_1 \pm Y_1) = 2 - 2 |\rho(X, Y)| = 2 - 2 \cdot 1 = 2 - 2 = 0 \Rightarrow X_1 - Y_1 = C(const)$

    $\mathbb{M}(X_1 \pm Y_1) = \mathbb{M}_C = 0$

    $C = 0 \Rightarrow X_1 = Y_1 \Rightarrow \dfrac{X - \mathbb{M}_X}{\sigma_X} = \dfrac{Y - \mathbb{M}_Y}{\sigma_Y}$

    Выразим $Y: Y = \pm \dfrac{\sigma_Y}{\sigma_X}X - \dfrac{\sigma_Y}{\sigma_X}\mathbb{M}_X + \mathbb{M}_Y$

    Обозначим, что $\pm \dfrac{\sigma_Y}{\sigma_X} = a, \ \dfrac{\sigma_Y}{\sigma_X}\mathbb{M}_X + \mathbb{M}_Y = b,$ тогда выражение сходится к $Y = aX + B.$
    :::
4) *Из независимости следует некоррелируемость, а обратное вообще говоря неверно. (Обратное верно для нормального закона.)

### Ковариационная и корреляционная матрицы

::: info `def` Ковариационная матрица
Матрица, состоящая из коэффициентов ковариации.

| $\mathbb{D}_X$ | $\text{cov}(X,Y)$ |
|:---:|:---:|
|$\text{cov}(X,Y)$|$\mathbb{D}_X$|

:::

*Из таблицы очевидно, что ковариация случайной величины самой с собой равна ее дисперсии. Но можно это и доказать:*

::: details `prf` Доказательство
Пусть X - случайная величина.
$\text{cov}(X, X) = \mathbb{M}[(X - \mathbb{M}_X)(X - \mathbb{M}_X)] = \mathbb{M}[X - \mathbb{M}_X]^2 = \mathbb{D}_X$ по определению дисперсии.
:::


::: info `def` Корреляционная матрица
Матрица, состоящая из парных коэффициентов корреляции.

| $1$ | $\rho(X,Y)$ |
|:---:|:---:|
|$\rho(X,Y)$|$1$|

:::

*Докажем, что корреляция случайной величины самой с собой равна 1, если случайная величина не равняется константе:*

::: details `prf` Доказательство
Пусть X - случайная величина, $X \neq const$.
$\text{cov}(X, X) = \mathbb{M}[(X - \mathbb{M}_X)(X - \mathbb{M}_X)] = \mathbb{M}[X - \mathbb{M}_X]^2 = \mathbb{D}_X$ по определению дисперсии.

Подставим в формулу коэффициента корреляции:

$\rho_{X,X} = \dfrac{\text{cov}(X, X)}{\sqrt{\mathbb{D}(X) \mathbb{D}(X)}} = \dfrac{\mathbb{D}(X)}{\sqrt{\mathbb{D}(X)^2}} = \dfrac{\mathbb{D}(X)}{\mathbb{D}(X)} = 1.$
:::

Почему мы не можем считать коэффициент корреляции для константы? Все просто: дисперсия константы равня 0, а корреляция не имеет смысла, так как знаменатель в формуле корреляции равен нулю.